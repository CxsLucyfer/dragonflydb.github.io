<!doctype html><html lang=en-us class=h-100><head><meta charset=utf-8><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta name=viewport content="width=device-width,initial-scale=1"><title>Redis Analysis - Part 2: Simplicity</title><meta name=author content="Dragonfly"><meta name=keywords content="dragonfly,in-memory,datastore,scale"><meta name=description content="Dragonfly - Scalable in-memory datastore made simple"><meta name=generator content="Hugo 0.101.0"><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3 crossorigin=anonymous><link rel=preload href=/scss/main.min.b68a21dab2adc03b59da7ff5f7d1bd093c706f611b63e56f75392b28a8f0dfb7.css as=style><link href=/scss/main.min.b68a21dab2adc03b59da7ff5f7d1bd093c706f611b63e56f75392b28a8f0dfb7.css rel=stylesheet integrity><link href='//fonts.googleapis.com/css?family=Poppins:600,700,800,900' rel=stylesheet type=text/css><link href='//fonts.googleapis.com/css?family=Lato:100,300,400' rel=stylesheet type=text/css><link rel="shortcut icon" href=/img/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/img/apple-touch-icon.png><meta property="og:locale" content="en_us"><meta property="og:site_name" content="Dragonfly"><meta property="og:title" content="Redis Analysis - Part 2: Simplicity"><meta property="og:type" content="article"><meta property="og:url" content="https://www.dragonflydb.io/blog/2022/01/30/simple_is_beatiful/"><meta property="og:description" content="Dragonfly - Scalable in-memory datastore made simple"><meta property="og:image" content="https://www.dragonflydb.io/img/banners/simple.jpg"><meta property="og:image:type" content="image/jpg"><meta property="og:image:width" content="592"><meta property="og:image:height" content="284"><meta property="og:updated_time" content="2022-01-30T20:00:00+0200"><meta property="article:section" content="Engineering"><meta property="article:published_time" content="2022-01-30T20:00:00+0200"><meta property="article:modified_time" content="2022-01-30T20:00:00+0200"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@AttosIO"><meta name=twitter:title content="Redis Analysis - Part 2: Simplicity"><meta name=twitter:image content="https://www.dragonflydb.io/img/banners/simple.jpg"><meta name=twitter:description content="Dragonfly - Scalable in-memory datastore made simple"></head><body class="d-flex flex-column h-100"><div class=flex-shrink-0><nav class="navbar navbar-expand-md navbar-light shadow-sm main-nav"><div class=container-lg><a class=navbar-brand href=/><img src=/img/logo.svg alt="Redis Analysis - Part 2: Simplicity  logo" class=my-auto></a>
<button class="navbar-toggler collapsed" type=button data-bs-toggle=collapse data-bs-target=.navbar-collapse aria-controls=navbarNavAltMarkup aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-end"><div class=navbar-nav><a class=nav-link zgotmplz href=/platform/>Platform</a>
<a class="nav-link active" zgotmplz href=/blog/>Blog</a>
<a class=nav-link zgotmplz href=/careers/>Careers</a>
<a class="nav-link git-icon" zgotmplz href=https://github.com/dragonflydb/dragonfly>Git</a>
<a target=_blank href=https://github.com/dragonflydb/dragonfly/blob/main/docs/quick-start/README.md class="btn btn-primary btn-get-started">Get Dragonfly</a></div></div></div></nav><main class=mx-auto style=max-width:2000px><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><div id=blog-post class=pt-5><div class=container><div class="row blog_header"><div class="col-2 d-none d-lg-flex"><a href=javascript:history.back() class="btn btn-outline-dark my-auto">&lt; Back</a></div><div class=col><span class=category_label>Engineering</span><h1>Redis Analysis - Part 2: Simplicity</h1><h6 class="card-subtitle mb-2">January 30, 2022
By <a href=/authors/roman-gershman>Roman Gershman</a></h6></div><div class="col-2 d-none d-lg-flex"></div></div><div class=row><div class="col-2 d-none d-lg-flex"></div><div class=col><div id=post-content><p>Let&rsquo;s talk about the simplicity of Redis.
Redis was initially designed as a simple store, and it seems that its APIs achieved this goal.
Unfortunately, Redis&rsquo;s simple design makes it unreliable and difficult to manage in production.</p><p>So the question is - what simplicity means to you as a datastore user?</p><p>Before diving into Redis specifics, a disclosure: some of the problems I mention below
do not show up for small workloads. For those of you, who have managed Redis instances
larger than 12GB, please answer the following questions:</p><ul><li><p>There are eight Redis cache eviction policies. How well do you know them? Are you happy with either
one of them?</p></li><li><p>How confident are you when you need to change Redis settings, especially
those that control its memory consumption? Can you guarantee what its peak memory usage will be?</p></li><li><p>Have you ever needed to debug an unresponsive Redis instance or a its OOM crash? How easy was it?</p></li><li><p>Have you ever observed connection overload events when multiple clients connect to a redis instance?</p></li></ul><p>Fourteen years after Redis&rsquo;s inception, we&rsquo;ve established that the engineering community demands
a simple, low-latency Redis-like API that compliments relational databases. However, the community is unlikely to settle with a fragile technology that is hard to manage. API simplicity does not mean that the foundation should not be solid.</p><p>I was fortunate to observe Redis and Memcached usage globally, so
my opinion was shaped by looking at the whole range of workloads:
I&rsquo;ve seen how those &ldquo;simple&rdquo; design decisions in Redis
caused a sub-optimal but manageable quirks with 4-16GB workloads, made it painful at 64GB scale,
and caused frustration and a lack of trust with 100+ GB workloads.</p><h2 id=redis-caching>Redis Caching</h2><p>I mentioned cache policy already. It&rsquo;s one of more significant settings in Redis when used as a cache (a pretty popular use-case for Redis). In a perfect world, a regular user of Redis would love to have a magical cache that does the following:</p><ul><li>Reclaims expired items instead of growing in memory. btw, this requirement holds for non-cache scenarios as well.</li><li>similarly, does not evict non-expired entries if there is a sinificant number of expired items that
could be evicted instead.</li><li>maximizes hit-ratio in a robust manner by keeping entries that are most likely to be hit in the future.</li></ul><p>A normal user does not want to know what LFU or LRU is, or why Redis implements
guesstimate of those heuristics or why it can not evict expired items efficiently.
In reality, not only that the user is expected to know the internal implementation details
of the Redis cache algorithms, he also needs to decide between eight &ldquo;simple&rdquo; options of <code>maxmemory-policy</code> setting.<figure><img src=img/choices.jpg alt="redis settings" width=350px></figure></p><h2 id=persistence>Persistence</h2><p>If I had to pick a single design choice that looked &ldquo;simple&rdquo; at the time
yet had a substantial negative impact on the reliability of the whole system and the complexity of other features - it would be the fork-based BGSAVE command. The BGSAVE algorithm allows Redis to produce a point-in-time snapshotting of in-memory data or sync with its secondary replica. Redis does it by forking the serialization routine into a child process. By doing so, this child process gets an immutable, point-in-time snapshot of its parent process memory from Linux for &ldquo;free&rdquo;. Redis relies on Linux property that does not copy the physical memory during <code>fork()</code> but uses lazy Copy-On-Write operation instead.</p><p>Using the OS to achieve consistent snapshot isolation looks like an elegant choice at first sight. However, there are some serious problems with this approach:</p><ol><li><strong>Lack of back-pressure</strong> When the Redis parent process mutates its entries, it in fact duplicates the Linux memory pages with CoW. CoW is transparent to the parent process; therefore
the Redis memory component has a hard time estimating its actual memory usage.
And even if it did, there is no efficient mechanism in Redis to &ldquo;postpone&rdquo; or stall the incoming writes - the execution thread must progress with the flow. Under the heavy writes, this will easily
cause OOM crashes. <img src=img/bgsave.gif alt=bgsave></li><li><strong>Unbounded memory overhead</strong> In the worst case, both child and parent processes could double
Redis physical memory. Unfortunately, it does not stop there with replica syncs: the parent must also hold the replication log of mutations during the snapshot, which grows in memory until the sync completes. In addition, the parent dataset can grow beyond its initial size because the user continues adding items.
These factors can contribute to RSS usage spiking wildly under different write loads or database sizes. All this makes it very hard to estimate the
maximum memory usage for Redis.<figure><img src=img/boromir.jpg alt="boromir knows" width=300px></figure></li><li><strong>Linux large pages</strong> Enabling large pages usually improves the database performance; however, with Redis and bgsave, huge pages would create high write amplification - a tiny write would cause 2MB or 1GB CoW. This would quickly cause 100% memory overhead and major latency spikes during writes.</li><li><strong>Bad interactions with other Redis features</strong> Ask Redis maintainers how hard it was to implement TLS support in Redis 6. The seemingly unrelated feature had several problems due to how the TLS session interacted with the <code>fork()</code> call. As a result: TLS in Redis has mediocre performance.</li></ol><p>So far, I&rsquo;ve mentioned a few stability problems with Redis that are impossible to fix
with the current Redis architecture. There is a long tail of additional problems that hurt Redis reliability, impact its resource usage or obscure its API guarantees. Here are some of them in random order:</p><ul><li>Unreliable replica syncs: if the master&rsquo;s replication buffer overflows during replica sync,
the replica will retry the whole synchronization flow, possibly entering the infinite cycle of never-ending attempts.</li><li>Unreliable timeouts in blocking commands: blocking commands can expire with timeouts much larger than specified.</li><li>Uncontrolled freezes: commands like <code>FLUSHDB</code> will &ldquo;stop the world&rdquo; during their execution.
This means Redis may completely stall the processing of ongoing requests for minutes or longer.</li><li>LUA stalling: a similar problem with unresponsiveness exists when running bad LUA scripts.
Moreover, even good scripts may cause significant delays to other concurrent requests due to the sequential nature of Redis execution.</li><li>PUB/SUB is unreliable and prone to data loss when a SUB client disconnects.</li></ul><h2 id=fight-against-complexity>Fight against complexity</h2><p>I think it&rsquo;s time to redesign the system that once challenged traditional databases but nowadays suffers
from complexity itself.</p><p>Lately, I&rsquo;ve been working on a novel design of a cache and dictionary
data structures that could be the foundation stones for the next-generation memory store.
The work is still in progress, but it already shows some promising results.
The cache design is so novel that I think it deserves a blog post of its own. Therefore, today I will share just the basic characteristics of the underlying dictionary.</p><p>Below you can see a Redis 6.2 vs my experimental store (POC), both running on a dedicated 64-cpu n2d instance in GCP.</p><p>I run the same three commands on both servers: <code>debug populate</code>, <code>save</code> and <code>flushdb</code>. <code>populate</code> is interesting because it demonstrates the raw efficiency of the underlying engine,
without bottlenecks like networking. <code>save</code> and <code>flushdb</code> are interesting because both
are &ldquo;stop the world&rdquo; commands that must process the whole database and their performance directly affects
database robustness.</p><figure><img src=img/redis_table.png alt="redis 6.2" width=350px></figure><p>As you can see it takes almost 180s to create 200M items in Redis. What&rsquo;s remarkable about this number
is that it sets an upper bound on write throughput limit for Redis: no matter how big the Redis server is,
it won&rsquo;t be able to go faster than ~1.1M records a second because records creation is always done entirely in a single thread. Saving 200M records takes 150s which shows how quickly a server can persist its data or replicate itself to a replica. Note the gap: those 200M items take up 17GB of RAM,
hence Redis moves 17GB in 150s or 110MB/s (for comparison, the slowest hdd in AWS (sc1)
reaches 250MB/s and in GCP (pd-standard) reaches 400MB/s).
Finally, <code>flushdb</code> demonstrates that a simple &ldquo;empty my store&rdquo;
operation may be cpu-intensive, and completely stall other requests for almost 3 minutes!
Not so simple anymore.</p><p>This snapshot below is the POC store under development.<figure><img src=img/df_table2.png alt=POC width=500px></figure>You can see that the same commands run an order of magnitude faster. The result is achieved in part
because of the <a href=https://www.dragonflydb.io/blog/2021/12/09/single_threaded_redis/>shared-nothing architecture</a> that distributes operations across cpus but also due to novel
dictionary design. Btw, you can see that <code>flushdb</code> operation was not timed - <code>redis-cli</code> does not show
latencies of &ldquo;fast&rdquo; operations below 500ms. Hence, we can conclude that <code>flushdb</code> was at least 350 times faster in this case. If you compare <code>used_memory_human</code> metric, you can see that Redis
required almost twice more RAM than the POC (16.9GB vs 9.5GB).</p><p>There is a lot more to cover. For example, Redis <code>SAVE</code> stalls the processing of all requests,
similarly to <code>FLUSHDB</code> . In contrast, the new store runs it concurrently with the rest of the traffic while still producing a consistent point-in-time snapshot. In other words, it provides <code>BGSAVE</code> product experience with the reliability of <code>SAVE</code>.</p><p>If we combine the long tail of improvements that come from a new design, we will get a product
that redefines what simplicity and ease of use mean for an in-memory database world.</p></div></div><div class="col-2 d-none d-lg-flex"></div></div></div></div></main></div><footer id=copyright class="footer mt-auto py-3"><div class=container><div class=row><div class=col-12><img src=/img/icon.svg></div></div><div class=row><div class=col-6><p><a href=https://twitter.com/romanger><i class="fa-brands fa-twitter"></i></a>
<a href=mailto:info@attos.io><i class="fa-solid fa-at"></i></a>
<a href=https://github.com/dragonflydb/dragonfly><i class="fa-brands fa-github"></i></a></p><p><a href=/privacy/>Privacy Policy</a></p><p>Copyright (c) 2022, Attos Technologies Ltd; all rights reserved.</p></div><div class=col-6><small>* Redis is a trademark of Redis Ltd. Any rights therein are reserved to Redis Ltd. Any use by Attos is for referential purposes only and does not indicate any sponsorship, endorsement or affiliation between Redis and Attos.</small></div></div></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-EZMGVEP6RT"></script>
<script>var dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-EZMGVEP6RT",{anonymize_ip:!1})}</script><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js integrity=sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p crossorigin=anonymous></script></body></html>